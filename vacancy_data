from bs4 import BeautifulSoup as bs
import requests
import re
import pandas as pd
import json
from pymongo import MongoClient
from pprint import pprint


class VacancyBank:
    def __init__(self, target):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/90.0.4430.93'
        }
        self.hh_url = 'https://hh.ru/search/vacancy'
        self.target = target
        self.parser_result = self.parser_hh(target)

    def parser_hh(self, target):
        parser_result = []
        params = {
            'text': target,
            'search_field': 'name',
            'items_on_page': '50',
            'page': 0
        }

        for page_number in range(0, 100):
            params['page'] = page_number
            response = requests.get(self.hh_url, params=params, headers=self.headers)
            target_page = bs(response.text, 'html.parser')
            vacancy_list = target_page.find_all(
                'div', {'class': 'vacancy-serp-item'})
            try:
                target_page.find('a', {'data-qa': 'pager-next'}).find('span')
                for vacancy in vacancy_list:
                    parser_result.append(self.get_item_info(vacancy))
            except:
                break
        return parser_result

    def hh_get_vacancy_info(self, element):
        vacancy_date = {}
        # vacancy_name
        vacancy_name = element.find(
            'a', {
                'data-qa': 'vacancy-serp__vacancy-title'}).getText().replace(u'\xa0', u' ')
        vacancy_date['vacancy_name'] = vacancy_name
        # employer_name
        employer_name = element.find(
            'a', {
                'data-qa': 'vacancy-serp__vacancy-employer'}).getText().replace(
            u'\xa0', u' ').split(', ')[0]
        vacancy_date['employer_name'] = employer_name
        # city
        city = element.find(
            'span', {
                'data-qa': 'vacancy-serp__vacancy-address'}).getText().split(', ')[0]
        vacancy_date['city'] = city
        # metro_name
        metro_name = element.find('span', {'class': 'metro-station'})
        if not metro_name:
            metro_name = None
        else:
            metro_name = metro_name.getText()
        vacancy_date['metro_name'] = metro_name
        # salary
        salary = element.find(
            'span', {
                'data-qa': 'vacancy-serp__vacancy-compensation'})
        salary_currency = None
        if not salary:
            salary_min = None
            salary_max = None
            salary_currency = None
        else:
            salary = salary.getText().replace(u'\u202f', u'')
            salary = re.split(r'\s|-', salary)
            if salary[0] == 'до':
                salary_min = None
                salary_max = int(salary[1])
                salary_currency = str(salary[2])
            elif salary[0] == 'от':
                salary_min = int(salary[1])
                salary_max = None
            else:
                salary_min = int(salary[0])
                salary_max = int(salary[2])
                salary_currency = str(salary[3])
        vacancy_date['salary_min'] = salary_min
        vacancy_date['salary_max'] = salary_max
        vacancy_date['salary_currency'] = salary_currency
        # vacancy_link
        vacancy_link = element.find(
            'a', {'data-qa': 'vacancy-serp__vacancy-title'}).get('href').split('?')[0]
        vacancy_date['vacancy_link'] = vacancy_link
        vacancy_date['site_address'] = 'https://hh.ru'
        return vacancy_date


    def _parser_superjob(vacancy):
        global page_block
        vacancy_date = []

        params = {
            'keywords': vacancy,
            'profession_only': '1',
            'geo[c][0]': '15',
            'geo[c][1]': '1',
            'geo[c][2]': '9',
            'page': ''
        }

        headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0'
        }

        link = 'https://www.superjob.ru/vacancy/search/'

        html = requests.get(link, params=params, headers=headers)

        if html.ok:
            parsed_html = bs(html.text, 'html.parser')

            page_block = parsed_html.find('a', {'class': 'f-test-button-1'})
        if not page_block:
            last_page = 1
        else:
            page_block = page_block.findParent()
            last_page = int(page_block.find_all('a')[-2].getText())

        for page in range(0, last_page + 1):
            params['page'] = page
            html = requests.get(link, params=params, headers=headers)

            if html.ok:
                parsed_html = bs(html.text, 'html.parser')
                vacancy_items = parsed_html.find_all('div', {'class': 'f-test-vacancy-item'})

                for item in vacancy_items:
                    vacancy_date.append(_parser_item_superjob(item))

        return vacancy_date


    def _parser_item_superjob(item):
        vacancy_date = {}

        # vacancy_name
        vacancy_name = item.find_all('a')
        if len(vacancy_name) > 1:
            vacancy_name = vacancy_name[-2].getText()
        else:
            vacancy_name = vacancy_name[0].getText()
        vacancy_date['vacancy_name'] = vacancy_name

        # company_name
        company_name = item.find('span', {'class': 'f-test-text-vacancy-item-company-name'})

        if item.find('') != -1:
            company_name = None
        else:
            company_name = item.find('span', {'class': 'f-test-text-vacancy-item-company-name'}).getText()

        vacancy_date['company_name'] = company_name

        # city
        company_location = item.find('span', {'class': 'f-test-text-company-item-location'}) \
            .findChildren()[1] \
            .getText() \
            .split(',')

        vacancy_date['city'] = company_location[0]

        # metro station
        if len(company_location) > 1:
            metro_station = company_location[1]
        else:
            metro_station = None

        vacancy_date['metro_station'] = metro_station

        # salary
        salary = item.find('span', {'class': 'f-test-text-company-item-salary'}).findChildren()
        if item.find('По договорённости') != -1:
            salary_min = None
            salary_max = None
            salary_currency = None
        else:
            salary_currency = salary[-1].getText()
            is_check_salary = item.find('span', {'class': 'f-test-text-company-item-salary'}).getText().split('\xa0')
            if is_check_salary == 'до' or len(salary) == 2:
                salary_min = None
                salary_max = int(salary[0].getText())
            elif is_check_salary == 'от':
                salary_min = int(salary[0].getText())
                salary_max = None
            else:
                salary_min = int(salary[0].getText()).split('\xa0')
                salary_max = int(salary[2].getText())
        vacancy_date['salary_min'] = salary_min
        vacancy_date['salary_max'] = salary_max
        vacancy_date['salary_currency'] = salary_currency

        # link
        vacancy_link = item.find_all('a')

        if len(vacancy_link) > 1:
            vacancy_link = vacancy_link[-2]['href']
        else:
            vacancy_link = vacancy_link[0]['href']

        vacancy_date['vacancy_link'] = f'https://www.superjob.ru{vacancy_link}'

        # site
        vacancy_date['site'] = 'www.superjob.ru'

        return vacancy_date

    def parser_vacancy(vacancy):
        vacancy_date = {}
        vacancy_date.extend(_parser_hh(vacancy))
        vacancy_date.extend(_parser_superjob(vacancy))

        df = pd.DataFrame(vacancy_date)

        return df


    # vacancy = 'Python'
    # df = parser_vacancy(vacancy)

    # df